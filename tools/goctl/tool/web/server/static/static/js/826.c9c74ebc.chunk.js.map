{"version":3,"file":"static/js/826.c9c74ebc.chunk.js","mappings":"yFAAA,SAASA,EAAWC,GAClB,OAAO,IAAIC,OAAO,MAAQD,EAAME,KAAK,OAAS,QAChD,C,yDAEA,IAAIC,EAAgBJ,EAAW,CAAC,MAAO,KAAM,MAAO,OAChDK,EAAiB,CAAC,KAAM,SAAU,QAAS,QAAS,WAClC,MAAO,MAAO,OAAQ,OAAQ,SAAU,UACxC,MAAO,OAAQ,SAAU,KAAM,SAC/B,SAAU,OAAQ,QAAS,SAC3B,MAAO,QAAS,OAAQ,QAAS,KAAM,QAAS,QAClEC,EAAiB,CAAC,MAAO,MAAO,MAAO,MAAO,OAAQ,YAAa,WAAY,MAC7D,cAAe,UAAW,UAAW,UAAW,OAAQ,MAAO,SAC/D,YAAa,OAAQ,SAAU,QAAS,SAAU,YAClD,UAAW,UAAW,UAAW,OAAQ,OAAQ,MAAO,KACxD,QAAS,MAAO,aAAc,aAAc,OAAQ,MACpD,OAAQ,SAAU,MAAO,MAAO,aAAc,MAAO,OACrD,SAAU,MAAO,OAAQ,MAAO,MAAO,WAAY,QACnD,OAAQ,WAAY,QAAS,MAAO,UAAW,QAC/C,SAAU,eAAgB,MAAO,MAAO,QAAS,QACjD,OAAQ,OAAQ,MAAO,aAAc,iBACrC,WAAY,aAElC,SAASC,EAAIC,GACX,OAAOA,EAAMC,OAAOD,EAAMC,OAAOC,OAAS,EAC5C,CAEO,SAASC,EAASC,GAOvB,IANA,IAAIC,EAAa,QAEbC,EAAaF,EAAWE,YAAcF,EAAWG,kBAAoB,4BAErEC,EAAY,CAACJ,EAAWK,gBAAiBL,EAAWM,gBAAiBN,EAAWO,iBAAkBP,EAAWQ,iBAChGR,EAAWI,WAAa,0DAChCK,EAAI,EAAGA,EAAIL,EAAUN,OAAQW,IAAUL,EAAUK,IAAIL,EAAUM,OAAOD,IAAK,GAEpF,IAAIE,EAAgBX,EAAWW,cAE3BC,EAAanB,EAAgBoB,EAAanB,OACboB,GAA7Bd,EAAWe,iBACbH,EAAaA,EAAWI,OAAOhB,EAAWe,sBAEXD,GAA7Bd,EAAWiB,iBACbJ,EAAaA,EAAWG,OAAOhB,EAAWiB,iBAE5C,IAAIC,IAAQlB,EAAWmB,SAAWC,OAAOpB,EAAWmB,SAAW,GAC/D,GAAID,EAAK,CAEP,IAAIG,EAAcrB,EAAWqB,aAAc,oDAC3CT,EAAaA,EAAWI,OAAO,CAAC,WAAY,OAAQ,QAAS,QAAS,QAAS,QAAS,aAAc,QAAS,SAC/GH,EAAaA,EAAWG,OAAO,CAAC,QAAS,QAAS,OAAQ,UAC1D,IAAIM,EAAiB,IAAIhC,OAAO,qDAAsD,IACxF,KAAO,CACD+B,EAAcrB,EAAWqB,aAAc,0BAC3CT,EAAaA,EAAWI,OAAO,CAAC,OAAQ,UACxCH,EAAaA,EAAWG,OAAO,CAAC,QAAS,aAAc,SAAU,MAAO,SAAU,WAClD,OAAQ,SAAU,OAAQ,YAAa,SAAU,SACjD,SAAU,UAAW,SAAU,SAC3DM,EAAiB,IAAIhC,OAAO,2CAA4C,IAC9E,CACA,IAAIiC,EAAWnC,EAAWwB,GACtBY,EAAWpC,EAAWyB,GAG1B,SAASY,EAAUC,EAAQ9B,GACzB,IAAI+B,EAAMD,EAAOC,OAA4B,MAAnB/B,EAAMgC,UAGhC,GAFID,IAAK/B,EAAMiC,OAASH,EAAOI,eAE3BH,GAA0B,MAAnBhC,EAAIC,GAAOmC,KAAc,CAClC,IAAIC,EAAcrC,EAAIC,GAAOqC,OAC7B,GAAIP,EAAOQ,WAAY,CACrB,IAAIC,EAAaT,EAAOI,cAKxB,OAJIK,EAAaH,EACfI,EAAYV,EAAQ9B,GACbuC,EAAaH,GAAeK,EAAOX,EAAQ9B,IAA2B,KAAjB8B,EAAOY,SACnE1C,EAAM2C,YAAa,GACd,IACT,CACE,IAAIC,EAAQC,EAAef,EAAQ9B,GAGnC,OAFIoC,EAAc,GAAKK,EAAOX,EAAQ9B,KACpC4C,GAAS,IAAMvC,GACVuC,CAEX,CACA,OAAOC,EAAef,EAAQ9B,EAChC,CAEA,SAAS6C,EAAef,EAAQ9B,EAAO8C,GACrC,GAAIhB,EAAOQ,WAAY,OAAO,KAG9B,IAAKQ,GAAYhB,EAAOiB,MAAM,QAAS,MAAO,UAG9C,GAAIjB,EAAOiB,MAAM,YAAY,GAAQ,CACnC,IAAIC,GAAe,EAKnB,GAHIlB,EAAOiB,MAAM,iCAAkCC,GAAe,GAC9DlB,EAAOiB,MAAM,kBAAmBC,GAAe,GAC/ClB,EAAOiB,MAAM,YAAaC,GAAe,GACzCA,EAGF,OADAlB,EAAOmB,IAAI,MACJ,SAGT,IAAIC,GAAa,EAgBjB,GAdIpB,EAAOiB,MAAM,oBAAmBG,GAAa,GAE7CpB,EAAOiB,MAAM,gBAAeG,GAAa,GAEzCpB,EAAOiB,MAAM,iBAAgBG,GAAa,GAE1CpB,EAAOiB,MAAM,mCAEfjB,EAAOmB,IAAI,MAEXC,GAAa,GAGXpB,EAAOiB,MAAM,kBAAiBG,GAAa,GAC3CA,EAGF,OADApB,EAAOmB,IAAI,MACJ,QAEX,CAGA,GAAInB,EAAOiB,MAAMrB,GAEf,OADmE,IAAjDI,EAAOqB,UAAUC,cAAcC,QAAQ,MAKvDrD,EAAMsD,SAiCZ,SAA6BC,EAAWC,GACtC,KAAO,OAAOH,QAAQE,EAAUE,OAAO,GAAGL,gBAAkB,GAC1DG,EAAYA,EAAUG,OAAO,GAE/B,IAAIC,EAAiC,GAApBJ,EAAUrD,OACvB0D,EAAW,SAEf,SAASC,EAAgBC,GACvB,OAAO,SAAShC,EAAQ9B,GACtB,IAAI+D,EAAQlB,EAAef,EAAQ9B,GAAO,GAS1C,MARa,eAAT+D,IACsB,KAApBjC,EAAOqB,UACTnD,EAAMsD,SAAWO,EAAgBC,EAAQ,GACZ,KAApBhC,EAAOqB,YACDnD,EAAMsD,SAAjBQ,EAAQ,EAAoBD,EAAgBC,EAAQ,GAClCE,IAGnBD,CACT,CACF,CAEA,SAASC,EAAYlC,EAAQ9B,GAC3B,MAAQ8B,EAAOmC,OAEb,GADAnC,EAAOoC,SAAS,eACZpC,EAAOmB,IAAI,OAEb,GADAnB,EAAOqC,OACHR,GAAc7B,EAAOmC,MACvB,OAAOL,MACJ,IAAI9B,EAAOiB,MAAMQ,GAEtB,OADAvD,EAAMsD,SAAWE,EACVI,EACF,GAAI9B,EAAOiB,MAAM,MAEtB,OAAOa,EACF,GAAI9B,EAAOiB,MAAM,KAAK,GAG3B,OADA/C,EAAMsD,SAAWO,EAAgB,GAC7B/B,EAAOqB,UAAkBS,EACjB5D,EAAMsD,SAASxB,EAAQ9B,GAC9B,GAAI8B,EAAOiB,MAAM,MACtB,OAAOa,EACF,GAAI9B,EAAOiB,MAAM,KAEtB,OAAO1C,EAEPyB,EAAOmB,IAAI,OACb,CAEF,GAAIU,EAAY,CACd,GAAIvD,EAAWgE,uBACb,OAAO/D,EAEPL,EAAMsD,SAAWE,CACrB,CACA,OAAOI,CACT,CAEA,OADAI,EAAYK,UAAW,EAChBL,CACT,CA5FuBM,CAAoBxC,EAAOqB,UAAWnD,EAAMsD,UACtDtD,EAAMsD,SAASxB,EAAQ9B,KAJ9BA,EAAMsD,SAiGZ,SAA4BC,EAAWC,GACrC,KAAO,OAAOH,QAAQE,EAAUE,OAAO,GAAGL,gBAAkB,GAC1DG,EAAYA,EAAUG,OAAO,GAE/B,IAAIC,EAAiC,GAApBJ,EAAUrD,OACvB0D,EAAW,SAEf,SAASI,EAAYlC,EAAQ9B,GAC3B,MAAQ8B,EAAOmC,OAEb,GADAnC,EAAOoC,SAAS,WACZpC,EAAOmB,IAAI,OAEb,GADAnB,EAAOqC,OACHR,GAAc7B,EAAOmC,MACvB,OAAOL,MACJ,IAAI9B,EAAOiB,MAAMQ,GAEtB,OADAvD,EAAMsD,SAAWE,EACVI,EAEP9B,EAAOmB,IAAI,OACb,CAEF,GAAIU,EAAY,CACd,GAAIvD,EAAWgE,uBACb,OAAO/D,EAEPL,EAAMsD,SAAWE,CACrB,CACA,OAAOI,CACT,CAEA,OADAI,EAAYK,UAAW,EAChBL,CACT,CAhIuBO,CAAmBzC,EAAOqB,UAAWnD,EAAMsD,UACrDtD,EAAMsD,SAASxB,EAAQ9B,IAOlC,IAAK,IAAIa,EAAI,EAAGA,EAAIL,EAAUN,OAAQW,IACpC,GAAIiB,EAAOiB,MAAMvC,EAAUK,IAAK,MAAO,WAEzC,OAAIiB,EAAOiB,MAAMzC,GAAoB,cAEd,KAAnBN,EAAMgC,WAAoBF,EAAOiB,MAAMtB,GAClC,WAELK,EAAOiB,MAAMpB,IAAaG,EAAOiB,MAAMnD,GAClC,UAELkC,EAAOiB,MAAMnB,GACR,UAELE,EAAOiB,MAAM,iBACR,OAELjB,EAAOiB,MAAMtB,GACQ,OAAnBzB,EAAMgC,WAAyC,SAAnBhC,EAAMgC,UAC7B,MACF,YAITF,EAAOqC,OACArB,EAAW,KAAMzC,EAC1B,CAgGA,SAASmC,EAAYV,EAAQ9B,GAC3B,KAA0B,MAAnBD,EAAIC,GAAOmC,MAAcnC,EAAMC,OAAOuE,MAC7CxE,EAAMC,OAAOwE,KAAK,CAACpC,OAAQtC,EAAIC,GAAOqC,OAASP,EAAO4C,WACnCvC,KAAM,KACNwC,MAAO,MAC5B,CASA,SAASlC,EAAOX,EAAQ9B,GAEtB,IADA,IAAI4E,EAAW9C,EAAOI,cACflC,EAAMC,OAAOC,OAAS,GAAKH,EAAIC,GAAOqC,OAASuC,GAAU,CAC9D,GAAuB,MAAnB7E,EAAIC,GAAOmC,KAAc,OAAO,EACpCnC,EAAMC,OAAOuE,KACf,CACA,OAAOzE,EAAIC,GAAOqC,QAAUuC,CAC9B,CAEA,SAASC,EAAW/C,EAAQ9B,GACtB8B,EAAOC,QACT/B,EAAM8E,iBAAkB,EACxB9E,EAAMyC,QAAS,GAGjB,IAAIG,EAAQ5C,EAAMsD,SAASxB,EAAQ9B,GAC/BmD,EAAUrB,EAAOqB,UAGrB,GAAInD,EAAM8E,iBAA8B,KAAX3B,EAC3B,OAAOrB,EAAOiB,MAAMtB,GAAa,GAAS,OAASH,EAAM,WAAajB,EAgBxE,GAdI,KAAK0E,KAAK5B,KAAUnD,EAAM8E,iBAAkB,GAElC,YAATlC,GAAgC,WAATA,GACF,QAAnB5C,EAAMgC,YACXY,EAAQ,QAGK,QAAXO,GAAgC,UAAXA,IACvBnD,EAAMyC,QAAS,GAEF,UAAXU,IAAqBnD,EAAMgF,QAAS,GACzB,KAAX7B,IAAmBnD,EAAMgF,QAA6B,MAAnBjF,EAAIC,GAAOmC,MAAgBL,EAAOiB,MAAM,eAAe,IAC5FP,EAAYV,EAAQ9B,GAEA,GAAlBmD,EAAQjD,SAAgB,iBAAiB6E,KAAKnC,GAAQ,CACxD,IAAIqC,EAAkB,MAAM5B,QAAQF,GAKpC,IAJwB,GAApB8B,GA7CR,SAA0BnD,EAAQ9B,EAAOmC,GACvC,IAAIwC,EAAQ7C,EAAOiB,MAAM,uBAAuB,GAAS,KAAOjB,EAAOoD,SAAW,EAClFlF,EAAMC,OAAOwE,KAAK,CAACpC,OAAQrC,EAAMiC,QAAUlB,GAAiBe,EAAO4C,YAChDvC,KAAMA,EACNwC,MAAOA,GAC5B,CAyCMQ,CAAiBrD,EAAQ9B,EAAO,MAAMoF,MAAMH,EAAiBA,EAAgB,KAGvD,IADxBA,EAAkB,MAAM5B,QAAQF,IACL,CACzB,GAAIpD,EAAIC,GAAOmC,MAAQgB,EAClB,OAAO9C,EADoBL,EAAMiC,OAASjC,EAAMC,OAAOuE,MAAMnC,QAAUtB,GAAiBe,EAAO4C,WAEtG,CACF,CAIA,OAHI1E,EAAMyC,QAAUX,EAAOmC,OAA4B,MAAnBlE,EAAIC,GAAOmC,MAAgBnC,EAAMC,OAAOC,OAAS,GACnFF,EAAMC,OAAOuE,MAER5B,CACT,CAEA,MAAO,CACLyC,KAAM,SAENC,WAAY,WACV,MAAO,CACLhC,SAAUzB,EACV5B,OAAQ,CAAC,CAACoC,OAAQ,EAAGF,KAAM,KAAMwC,MAAO,OACxC1C,OAAQ,EACRD,UAAW,KACXgD,QAAQ,EACRvC,OAAQ,EAEZ,EAEA8C,MAAO,SAASzD,EAAQ9B,GACtB,IAAIwF,EAASxF,EAAM2C,WACf6C,IAAQxF,EAAM2C,YAAa,GAC/B,IAAIC,EAAQiC,EAAW/C,EAAQ9B,GAQ/B,OANI4C,GAAkB,WAATA,IACX5C,EAAMgC,UAAsB,WAATY,GAA+B,eAATA,EAA0Bd,EAAOqB,UAAYP,GAC3E,eAATA,IAAwBA,EAAQ,MAEhCd,EAAOmC,OAASjE,EAAMgF,SACxBhF,EAAMgF,QAAS,GACVQ,EAASnF,EAAauC,CAC/B,EAEAX,OAAQ,SAASjC,EAAOyF,EAAWC,GACjC,GAAI1F,EAAMsD,UAAYzB,EACpB,OAAO7B,EAAMsD,SAASe,SAAW,KAAO,EAE1C,IAAIsB,EAAQ5F,EAAIC,GACZ4F,EAAUD,EAAMxD,MAAQsD,EAAUhC,OAAO,IAC3B,MAAdkC,EAAMxD,OAAiBnC,EAAMyC,QAAU,kCAAkCsC,KAAKU,GAClF,OAAmB,MAAfE,EAAMhB,MACDgB,EAAMhB,OAASiB,EAAU,EAAI,GAE7BD,EAAMtD,QAAUuD,EAAU7E,GAAiB2E,EAAGG,KAAO,EAChE,EAEAC,aAAc,CACZC,aAAclG,EAAeuB,OAAOtB,GAAgBsB,OAAO,CAAC,OAAQ,UACpE4E,cAAe,+CACfC,cAAe,CAACC,KAAM,KACtBC,cAAe,CAACC,SAAU,CAAC,IAAK,IAAK,IAAK,IAAK,IAAK,MAAO,SAGjE,CAIO,MAAMC,EAASlG,EAAS,CAAC,GAEnBmG,EAASnG,EAAS,CAC7BgB,gBALmBoF,EAKG,6HALWA,EAAIC,MAAM,QAAjC,IAASD,C","sources":["../node_modules/@codemirror/legacy-modes/mode/python.js"],"sourcesContent":["function wordRegexp(words) {\n  return new RegExp(\"^((\" + words.join(\")|(\") + \"))\\\\b\");\n}\n\nvar wordOperators = wordRegexp([\"and\", \"or\", \"not\", \"is\"]);\nvar commonKeywords = [\"as\", \"assert\", \"break\", \"class\", \"continue\",\n                      \"def\", \"del\", \"elif\", \"else\", \"except\", \"finally\",\n                      \"for\", \"from\", \"global\", \"if\", \"import\",\n                      \"lambda\", \"pass\", \"raise\", \"return\",\n                      \"try\", \"while\", \"with\", \"yield\", \"in\", \"False\", \"True\"];\nvar commonBuiltins = [\"abs\", \"all\", \"any\", \"bin\", \"bool\", \"bytearray\", \"callable\", \"chr\",\n                      \"classmethod\", \"compile\", \"complex\", \"delattr\", \"dict\", \"dir\", \"divmod\",\n                      \"enumerate\", \"eval\", \"filter\", \"float\", \"format\", \"frozenset\",\n                      \"getattr\", \"globals\", \"hasattr\", \"hash\", \"help\", \"hex\", \"id\",\n                      \"input\", \"int\", \"isinstance\", \"issubclass\", \"iter\", \"len\",\n                      \"list\", \"locals\", \"map\", \"max\", \"memoryview\", \"min\", \"next\",\n                      \"object\", \"oct\", \"open\", \"ord\", \"pow\", \"property\", \"range\",\n                      \"repr\", \"reversed\", \"round\", \"set\", \"setattr\", \"slice\",\n                      \"sorted\", \"staticmethod\", \"str\", \"sum\", \"super\", \"tuple\",\n                      \"type\", \"vars\", \"zip\", \"__import__\", \"NotImplemented\",\n                      \"Ellipsis\", \"__debug__\"];\n\nfunction top(state) {\n  return state.scopes[state.scopes.length - 1];\n}\n\nexport function mkPython(parserConf) {\n  var ERRORCLASS = \"error\";\n\n  var delimiters = parserConf.delimiters || parserConf.singleDelimiters || /^[\\(\\)\\[\\]\\{\\}@,:`=;\\.\\\\]/;\n  //               (Backwards-compatibility with old, cumbersome config system)\n  var operators = [parserConf.singleOperators, parserConf.doubleOperators, parserConf.doubleDelimiters, parserConf.tripleDelimiters,\n                   parserConf.operators || /^([-+*/%\\/&|^]=?|[<>=]+|\\/\\/=?|\\*\\*=?|!=|[~!@]|\\.\\.\\.)/]\n  for (var i = 0; i < operators.length; i++) if (!operators[i]) operators.splice(i--, 1)\n\n  var hangingIndent = parserConf.hangingIndent;\n\n  var myKeywords = commonKeywords, myBuiltins = commonBuiltins;\n  if (parserConf.extra_keywords != undefined)\n    myKeywords = myKeywords.concat(parserConf.extra_keywords);\n\n  if (parserConf.extra_builtins != undefined)\n    myBuiltins = myBuiltins.concat(parserConf.extra_builtins);\n\n  var py3 = !(parserConf.version && Number(parserConf.version) < 3)\n  if (py3) {\n    // since http://legacy.python.org/dev/peps/pep-0465/ @ is also an operator\n    var identifiers = parserConf.identifiers|| /^[_A-Za-z\\u00A1-\\uFFFF][_A-Za-z0-9\\u00A1-\\uFFFF]*/;\n    myKeywords = myKeywords.concat([\"nonlocal\", \"None\", \"aiter\", \"anext\", \"async\", \"await\", \"breakpoint\", \"match\", \"case\"]);\n    myBuiltins = myBuiltins.concat([\"ascii\", \"bytes\", \"exec\", \"print\"]);\n    var stringPrefixes = new RegExp(\"^(([rbuf]|(br)|(rb)|(fr)|(rf))?('{3}|\\\"{3}|['\\\"]))\", \"i\");\n  } else {\n    var identifiers = parserConf.identifiers|| /^[_A-Za-z][_A-Za-z0-9]*/;\n    myKeywords = myKeywords.concat([\"exec\", \"print\"]);\n    myBuiltins = myBuiltins.concat([\"apply\", \"basestring\", \"buffer\", \"cmp\", \"coerce\", \"execfile\",\n                                    \"file\", \"intern\", \"long\", \"raw_input\", \"reduce\", \"reload\",\n                                    \"unichr\", \"unicode\", \"xrange\", \"None\"]);\n    var stringPrefixes = new RegExp(\"^(([rubf]|(ur)|(br))?('{3}|\\\"{3}|['\\\"]))\", \"i\");\n  }\n  var keywords = wordRegexp(myKeywords);\n  var builtins = wordRegexp(myBuiltins);\n\n  // tokenizers\n  function tokenBase(stream, state) {\n    var sol = stream.sol() && state.lastToken != \"\\\\\"\n    if (sol) state.indent = stream.indentation()\n    // Handle scope changes\n    if (sol && top(state).type == \"py\") {\n      var scopeOffset = top(state).offset;\n      if (stream.eatSpace()) {\n        var lineOffset = stream.indentation();\n        if (lineOffset > scopeOffset)\n          pushPyScope(stream, state);\n        else if (lineOffset < scopeOffset && dedent(stream, state) && stream.peek() != \"#\")\n          state.errorToken = true;\n        return null;\n      } else {\n        var style = tokenBaseInner(stream, state);\n        if (scopeOffset > 0 && dedent(stream, state))\n          style += \" \" + ERRORCLASS;\n        return style;\n      }\n    }\n    return tokenBaseInner(stream, state);\n  }\n\n  function tokenBaseInner(stream, state, inFormat) {\n    if (stream.eatSpace()) return null;\n\n    // Handle Comments\n    if (!inFormat && stream.match(/^#.*/)) return \"comment\";\n\n    // Handle Number Literals\n    if (stream.match(/^[0-9\\.]/, false)) {\n      var floatLiteral = false;\n      // Floats\n      if (stream.match(/^[\\d_]*\\.\\d+(e[\\+\\-]?\\d+)?/i)) { floatLiteral = true; }\n      if (stream.match(/^[\\d_]+\\.\\d*/)) { floatLiteral = true; }\n      if (stream.match(/^\\.\\d+/)) { floatLiteral = true; }\n      if (floatLiteral) {\n        // Float literals may be \"imaginary\"\n        stream.eat(/J/i);\n        return \"number\";\n      }\n      // Integers\n      var intLiteral = false;\n      // Hex\n      if (stream.match(/^0x[0-9a-f_]+/i)) intLiteral = true;\n      // Binary\n      if (stream.match(/^0b[01_]+/i)) intLiteral = true;\n      // Octal\n      if (stream.match(/^0o[0-7_]+/i)) intLiteral = true;\n      // Decimal\n      if (stream.match(/^[1-9][\\d_]*(e[\\+\\-]?[\\d_]+)?/)) {\n        // Decimal literals may be \"imaginary\"\n        stream.eat(/J/i);\n        // TODO - Can you have imaginary longs?\n        intLiteral = true;\n      }\n      // Zero by itself with no other piece of number.\n      if (stream.match(/^0(?![\\dx])/i)) intLiteral = true;\n      if (intLiteral) {\n        // Integer literals may be \"long\"\n        stream.eat(/L/i);\n        return \"number\";\n      }\n    }\n\n    // Handle Strings\n    if (stream.match(stringPrefixes)) {\n      var isFmtString = stream.current().toLowerCase().indexOf('f') !== -1;\n      if (!isFmtString) {\n        state.tokenize = tokenStringFactory(stream.current(), state.tokenize);\n        return state.tokenize(stream, state);\n      } else {\n        state.tokenize = formatStringFactory(stream.current(), state.tokenize);\n        return state.tokenize(stream, state);\n      }\n    }\n\n    for (var i = 0; i < operators.length; i++)\n      if (stream.match(operators[i])) return \"operator\"\n\n    if (stream.match(delimiters)) return \"punctuation\";\n\n    if (state.lastToken == \".\" && stream.match(identifiers))\n      return \"property\";\n\n    if (stream.match(keywords) || stream.match(wordOperators))\n      return \"keyword\";\n\n    if (stream.match(builtins))\n      return \"builtin\";\n\n    if (stream.match(/^(self|cls)\\b/))\n      return \"self\";\n\n    if (stream.match(identifiers)) {\n      if (state.lastToken == \"def\" || state.lastToken == \"class\")\n        return \"def\";\n      return \"variable\";\n    }\n\n    // Handle non-detected items\n    stream.next();\n    return inFormat ? null :ERRORCLASS;\n  }\n\n  function formatStringFactory(delimiter, tokenOuter) {\n    while (\"rubf\".indexOf(delimiter.charAt(0).toLowerCase()) >= 0)\n      delimiter = delimiter.substr(1);\n\n    var singleline = delimiter.length == 1;\n    var OUTCLASS = \"string\";\n\n    function tokenNestedExpr(depth) {\n      return function(stream, state) {\n        var inner = tokenBaseInner(stream, state, true)\n        if (inner == \"punctuation\") {\n          if (stream.current() == \"{\") {\n            state.tokenize = tokenNestedExpr(depth + 1)\n          } else if (stream.current() == \"}\") {\n            if (depth > 1) state.tokenize = tokenNestedExpr(depth - 1)\n            else state.tokenize = tokenString\n          }\n        }\n        return inner\n      }\n    }\n\n    function tokenString(stream, state) {\n      while (!stream.eol()) {\n        stream.eatWhile(/[^'\"\\{\\}\\\\]/);\n        if (stream.eat(\"\\\\\")) {\n          stream.next();\n          if (singleline && stream.eol())\n            return OUTCLASS;\n        } else if (stream.match(delimiter)) {\n          state.tokenize = tokenOuter;\n          return OUTCLASS;\n        } else if (stream.match('{{')) {\n          // ignore {{ in f-str\n          return OUTCLASS;\n        } else if (stream.match('{', false)) {\n          // switch to nested mode\n          state.tokenize = tokenNestedExpr(0)\n          if (stream.current()) return OUTCLASS;\n          else return state.tokenize(stream, state)\n        } else if (stream.match('}}')) {\n          return OUTCLASS;\n        } else if (stream.match('}')) {\n          // single } in f-string is an error\n          return ERRORCLASS;\n        } else {\n          stream.eat(/['\"]/);\n        }\n      }\n      if (singleline) {\n        if (parserConf.singleLineStringErrors)\n          return ERRORCLASS;\n        else\n          state.tokenize = tokenOuter;\n      }\n      return OUTCLASS;\n    }\n    tokenString.isString = true;\n    return tokenString;\n  }\n\n  function tokenStringFactory(delimiter, tokenOuter) {\n    while (\"rubf\".indexOf(delimiter.charAt(0).toLowerCase()) >= 0)\n      delimiter = delimiter.substr(1);\n\n    var singleline = delimiter.length == 1;\n    var OUTCLASS = \"string\";\n\n    function tokenString(stream, state) {\n      while (!stream.eol()) {\n        stream.eatWhile(/[^'\"\\\\]/);\n        if (stream.eat(\"\\\\\")) {\n          stream.next();\n          if (singleline && stream.eol())\n            return OUTCLASS;\n        } else if (stream.match(delimiter)) {\n          state.tokenize = tokenOuter;\n          return OUTCLASS;\n        } else {\n          stream.eat(/['\"]/);\n        }\n      }\n      if (singleline) {\n        if (parserConf.singleLineStringErrors)\n          return ERRORCLASS;\n        else\n          state.tokenize = tokenOuter;\n      }\n      return OUTCLASS;\n    }\n    tokenString.isString = true;\n    return tokenString;\n  }\n\n  function pushPyScope(stream, state) {\n    while (top(state).type != \"py\") state.scopes.pop()\n    state.scopes.push({offset: top(state).offset + stream.indentUnit,\n                       type: \"py\",\n                       align: null})\n  }\n\n  function pushBracketScope(stream, state, type) {\n    var align = stream.match(/^[\\s\\[\\{\\(]*(?:#|$)/, false) ? null : stream.column() + 1\n    state.scopes.push({offset: state.indent + (hangingIndent || stream.indentUnit),\n                       type: type,\n                       align: align})\n  }\n\n  function dedent(stream, state) {\n    var indented = stream.indentation();\n    while (state.scopes.length > 1 && top(state).offset > indented) {\n      if (top(state).type != \"py\") return true;\n      state.scopes.pop();\n    }\n    return top(state).offset != indented;\n  }\n\n  function tokenLexer(stream, state) {\n    if (stream.sol()) {\n      state.beginningOfLine = true;\n      state.dedent = false;\n    }\n\n    var style = state.tokenize(stream, state);\n    var current = stream.current();\n\n    // Handle decorators\n    if (state.beginningOfLine && current == \"@\")\n      return stream.match(identifiers, false) ? \"meta\" : py3 ? \"operator\" : ERRORCLASS;\n\n    if (/\\S/.test(current)) state.beginningOfLine = false;\n\n    if ((style == \"variable\" || style == \"builtin\")\n        && state.lastToken == \"meta\")\n      style = \"meta\";\n\n    // Handle scope changes.\n    if (current == \"pass\" || current == \"return\")\n      state.dedent = true;\n\n    if (current == \"lambda\") state.lambda = true;\n    if (current == \":\" && !state.lambda && top(state).type == \"py\" && stream.match(/^\\s*(?:#|$)/, false))\n      pushPyScope(stream, state);\n\n    if (current.length == 1 && !/string|comment/.test(style)) {\n      var delimiter_index = \"[({\".indexOf(current);\n      if (delimiter_index != -1)\n        pushBracketScope(stream, state, \"])}\".slice(delimiter_index, delimiter_index+1));\n\n      delimiter_index = \"])}\".indexOf(current);\n      if (delimiter_index != -1) {\n        if (top(state).type == current) state.indent = state.scopes.pop().offset - (hangingIndent || stream.indentUnit)\n        else return ERRORCLASS;\n      }\n    }\n    if (state.dedent && stream.eol() && top(state).type == \"py\" && state.scopes.length > 1)\n      state.scopes.pop();\n\n    return style;\n  }\n\n  return {\n    name: \"python\",\n\n    startState: function() {\n      return {\n        tokenize: tokenBase,\n        scopes: [{offset: 0, type: \"py\", align: null}],\n        indent: 0,\n        lastToken: null,\n        lambda: false,\n        dedent: 0\n      };\n    },\n\n    token: function(stream, state) {\n      var addErr = state.errorToken;\n      if (addErr) state.errorToken = false;\n      var style = tokenLexer(stream, state);\n\n      if (style && style != \"comment\")\n        state.lastToken = (style == \"keyword\" || style == \"punctuation\") ? stream.current() : style;\n      if (style == \"punctuation\") style = null;\n\n      if (stream.eol() && state.lambda)\n        state.lambda = false;\n      return addErr ? ERRORCLASS : style;\n    },\n\n    indent: function(state, textAfter, cx) {\n      if (state.tokenize != tokenBase)\n        return state.tokenize.isString ? null : 0;\n\n      var scope = top(state)\n      var closing = scope.type == textAfter.charAt(0) ||\n          scope.type == \"py\" && !state.dedent && /^(else:|elif |except |finally:)/.test(textAfter)\n      if (scope.align != null)\n        return scope.align - (closing ? 1 : 0)\n      else\n        return scope.offset - (closing ? hangingIndent || cx.unit : 0)\n    },\n\n    languageData: {\n      autocomplete: commonKeywords.concat(commonBuiltins).concat([\"exec\", \"print\"]),\n      indentOnInput: /^\\s*([\\}\\]\\)]|else:|elif |except |finally:)$/,\n      commentTokens: {line: \"#\"},\n      closeBrackets: {brackets: [\"(\", \"[\", \"{\", \"'\", '\"', \"'''\", '\"\"\"']}\n    }\n  };\n};\n\nvar words = function(str) { return str.split(\" \"); };\n\nexport const python = mkPython({})\n\nexport const cython = mkPython({\n  extra_keywords: words(\"by cdef cimport cpdef ctypedef enum except \"+\n                        \"extern gil include nogil property public \"+\n                        \"readonly struct union DEF IF ELIF ELSE\")\n})\n"],"names":["wordRegexp","words","RegExp","join","wordOperators","commonKeywords","commonBuiltins","top","state","scopes","length","mkPython","parserConf","ERRORCLASS","delimiters","singleDelimiters","operators","singleOperators","doubleOperators","doubleDelimiters","tripleDelimiters","i","splice","hangingIndent","myKeywords","myBuiltins","undefined","extra_keywords","concat","extra_builtins","py3","version","Number","identifiers","stringPrefixes","keywords","builtins","tokenBase","stream","sol","lastToken","indent","indentation","type","scopeOffset","offset","eatSpace","lineOffset","pushPyScope","dedent","peek","errorToken","style","tokenBaseInner","inFormat","match","floatLiteral","eat","intLiteral","current","toLowerCase","indexOf","tokenize","delimiter","tokenOuter","charAt","substr","singleline","OUTCLASS","tokenNestedExpr","depth","inner","tokenString","eol","eatWhile","next","singleLineStringErrors","isString","formatStringFactory","tokenStringFactory","pop","push","indentUnit","align","indented","tokenLexer","beginningOfLine","test","lambda","delimiter_index","column","pushBracketScope","slice","name","startState","token","addErr","textAfter","cx","scope","closing","unit","languageData","autocomplete","indentOnInput","commentTokens","line","closeBrackets","brackets","python","cython","str","split"],"sourceRoot":""}